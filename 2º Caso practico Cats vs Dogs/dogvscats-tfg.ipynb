{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n \n#  **Introducción**\n\n<font size = 4>\nEl presente notebook, recoge el procedimiento seguido para la creación del modelo y su posterior fase de entrenamiento, validación y test.  \n<br> <br>\n \nLa base de datos utilizada para la creación del clasificador de imágenes se denomina **Dogs vs Cats**. \n\n</font>","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, losses\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import BatchNormalization, Dropout, Conv2D, Flatten, Dense, MaxPooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom zipfile import ZipFile\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nimport os, re\nimport cv2\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-06-06T23:33:01.655546Z","iopub.execute_input":"2022-06-06T23:33:01.655963Z","iopub.status.idle":"2022-06-06T23:33:06.419752Z","shell.execute_reply.started":"2022-06-06T23:33:01.655823Z","shell.execute_reply":"2022-06-06T23:33:06.419072Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"\n<font size = 4>**Creacion de los dataframes y clasificacion de las imagenes** </font>\n","metadata":{}},{"cell_type":"code","source":"with ZipFile('../input/dogs-vs-cats/train.zip', 'r') as zip1:\n    zip1.extractall() \n    \nwith ZipFile('../input/dogs-vs-cats/test1.zip', 'r') as zip2:\n    zip2.extractall()\n\nfilenamesTrain = os.listdir(\"./train/\")\ncategoriesTrain = []\nfor filenameTrain in filenamesTrain:\n    if filenameTrain.startswith('dog'):\n        categoriesTrain.append('0') # DOG = 0\n    else:\n        categoriesTrain.append('1') # CAT = 1\n\nfor i in range(len(filenamesTrain)):\n    f = filenamesTrain[i].split(\".\")\n    if(len(f[0]) == 3):\n        F = f[0] + f[1]+ \".png\"\n        os.rename(\"./train/\"+filenamesTrain[i], \"./train/\"+F)   \n        filenamesTrain[i] = F\n        \ntrain_df = pd.DataFrame({\n    'filename': filenamesTrain,\n    'category': categoriesTrain\n})\n\nfilenamesTest = os.listdir(\"./test1\")   \n\ntest_df = pd.DataFrame({\n    'filename': filenamesTest\n})","metadata":{"execution":{"iopub.status.busy":"2022-06-06T23:33:09.568165Z","iopub.execute_input":"2022-06-06T23:33:09.568767Z","iopub.status.idle":"2022-06-06T23:33:32.600341Z","shell.execute_reply.started":"2022-06-06T23:33:09.568728Z","shell.execute_reply":"2022-06-06T23:33:32.598975Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Visualización de las imagenes del dataset** </font>","metadata":{}},{"cell_type":"code","source":"def plot_three_samples():\n    base_path = './train'\n    img_path = base_path + '/**'\n    path_contents = glob(img_path)\n    \n    plt.figure(figsize=(16,16))\n    imgs = random.sample(path_contents, 1)\n    plt.subplot(131)\n    plt.imshow(cv2.imread(imgs[0]))\n    return\nplot_three_samples()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Creacion del conjunto de entrenamiento, validación y test** </font>","metadata":{}},{"cell_type":"code","source":"imageWidht = 150\nimageHeight = 150\nimageChannels = 3\nnumClass = 2\nbatch_size = 100\n\nX_train2, X_val2 = train_test_split(train_df, test_size = 0.2)\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    X_train2,\n    directory=\"./train/\",\n    x_col='filename',\n    y_col='category',\n    target_size=(imageWidht,imageHeight),\n    class_mode=\"binary\",\n    batch_size=batch_size\n)\n\nval_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    X_val2,\n    directory=\"./train/\",\n    x_col='filename',\n    y_col='category',\n    target_size=(imageWidht,imageHeight),\n    class_mode=\"binary\",\n    batch_size=batch_size\n)\n\ntest_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntest_generator = val_datagen.flow_from_dataframe(\n    test_df,\n    directory=\"./test1/\",\n    x_col='filename',\n    y_col=None,\n    target_size=(imageWidht,imageHeight),\n    class_mode=None,\n    batch_size=batch_size,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T23:33:54.070199Z","iopub.execute_input":"2022-06-06T23:33:54.070537Z","iopub.status.idle":"2022-06-06T23:33:54.664110Z","shell.execute_reply.started":"2022-06-06T23:33:54.070499Z","shell.execute_reply":"2022-06-06T23:33:54.662543Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Creacion del modelo** </font>","metadata":{}},{"cell_type":"code","source":"input_shape = (imageWidht, imageHeight, imageChannels)\n\nmyModel = keras.Sequential(\n    [\n        layers.Conv2D(32, kernel_size = 4, strides = 2, activation=\"relu\", input_shape = input_shape),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        layers.Conv2D(64, kernel_size = 4, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, kernel_size = 4, strides = 2, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        layers.Conv2D(128, kernel_size = 4, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Conv2D(128, kernel_size = 4, padding='same', activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Conv2D(128, kernel_size = 4, strides = 2, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        layers.Conv2D(256, kernel_size = 4, strides = 2, padding='same', activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        layers.Flatten(),\n        layers.Dense(512, activation=\"relu\"),\n        layers.Dropout(0.3),\n        layers.Dense(2, activation=\"softmax\"),\n    ]\n   )\n\nmyModel.compile( optimizer='rmsprop', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\nmyModel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T00:02:46.399492Z","iopub.execute_input":"2022-06-07T00:02:46.401395Z","iopub.status.idle":"2022-06-07T00:02:46.879374Z","shell.execute_reply.started":"2022-06-07T00:02:46.401319Z","shell.execute_reply":"2022-06-07T00:02:46.877459Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Entrenamiento** </font>","metadata":{}},{"cell_type":"code","source":"early_stopping = EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=5, # how many epochs to wait before stopping\n    restore_best_weights=True,)\n\nbatch_size = 100\nepoch = 50\nlb = \"category\"\n\n\nhistory = myModel.fit(\n    train_generator,\n    validation_data=val_generator,\n    batch_size=batch_size,\n    validation_steps=X_val2.shape[0]//batch_size,\n    steps_per_epoch=X_train2.shape[0]//batch_size,\n    epochs=epoch,\n    callbacks=[early_stopping],\n    verbose=0, # suppress output since we'll plot the curves\n)\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[0:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n\nprint(max(history.history['accuracy']))\nprint(max(history.history['val_accuracy']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Almacenamiento del modelo entrenado** </font>","metadata":{}},{"cell_type":"code","source":"myModel.save('myModel.h5')\nmyModel.save_weights('myModel.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Carga del modelo entrenado** </font>","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\nmyModel = load_model('myModel.h5')\nmyModel.load_weights('myModel.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Predicción** </font>","metadata":{}},{"cell_type":"code","source":"predict = myModel.predict(test_generator, steps=np.ceil(test_df.shape[0]//batch_size))\n\ntest_df['category'] = np.argmax(predict, axis=-1)\n\nsample_test = test_df.head(18)\nsample_test.head()\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(\"./test1/\"+filename, target_size=(imageWidht,imageHeight))\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(\"Prediccion: \" + \"{}\".format(category) )\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}