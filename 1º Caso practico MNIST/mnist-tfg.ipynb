{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  **Introducción**\n\n<font size = 4>\nEl presente notebook, recoge el procedimiento seguido para la creación del modelo y su posterior fase de entrenamiento, validación y test.  \n<br> <br>\n \nLa base de datos utilizada para la creación del clasificador de imágenes se denomina **MNIST**. ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, losses\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import BatchNormalization, Dropout, Conv2D, Flatten, Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-01T11:21:25.27615Z","iopub.execute_input":"2022-06-01T11:21:25.276482Z","iopub.status.idle":"2022-06-01T11:21:30.939464Z","shell.execute_reply.started":"2022-06-01T11:21:25.276383Z","shell.execute_reply":"2022-06-01T11:21:30.938757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Creacion del conjunto de entrenamiento y test** </font>","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/digit-recognizer/test.csv')\ntrain = pd.read_csv('../input/digit-recognizer/train.csv')\n\nlb = \"label\"\nsc = 255.0\nnumClass = 10\nimageWidht = 28\nimageHeight = 28\nimageChannels = 1\n   \nY_train = train[lb]\nX_train = train.drop(labels = lb,axis = 1)\n\nX_train = X_train / sc\n\nX_test = test / sc\n\nY_train = to_categorical(Y_train, num_classes = numClass)\n\n\nX_train = X_train.values.reshape(-1,imageWidht,imageHeight,imageChannels)\nX_test = X_test.values.reshape(-1,imageWidht,imageHeight,imageChannels)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:31:20.510305Z","iopub.execute_input":"2022-06-01T11:31:20.510567Z","iopub.status.idle":"2022-06-01T11:31:24.128039Z","shell.execute_reply.started":"2022-06-01T11:31:20.510538Z","shell.execute_reply":"2022-06-01T11:31:24.12729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Visualización de las imagenes del dataset** </font>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# PREVIEW IMAGES\nplt.figure(figsize=(15,4.5))\nfor i in range(30):  \n    plt.subplot(3, 10, i+1)\n    plt.imshow(X_train[i].reshape((imageWidht,imageHeight)),cmap=plt.cm.binary)\n    plt.axis('off')\nplt.subplots_adjust(wspace=-0.1, hspace=-0.1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:22:23.705298Z","iopub.execute_input":"2022-06-01T11:22:23.70556Z","iopub.status.idle":"2022-06-01T11:22:24.944506Z","shell.execute_reply.started":"2022-06-01T11:22:23.705532Z","shell.execute_reply":"2022-06-01T11:22:24.943831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Creacion del modelo** </font>","metadata":{}},{"cell_type":"code","source":"#MY CODE\ninput_shape = (imageWidht,imageHeight,imageChannels)\n\nmyModel = keras.Sequential(\n    [\n        layers.Conv2D(32, kernel_size = 3, activation=\"relu\", input_shape = input_shape),\n        layers.BatchNormalization(),\n        layers.Conv2D(32, kernel_size = 3, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Conv2D(32, kernel_size = 5, strides=2, padding='same', activation=\"relu\"),\n        layers.Dropout(0.3),\n        layers.Conv2D(64, kernel_size = 3, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, kernel_size = 3, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, kernel_size = 5, strides=2, padding='same', activation=\"relu\"),\n        layers.Dropout(0.3),\n        layers.Conv2D(128, kernel_size = 4, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Flatten(),\n        layers.Dropout(0.3),\n        layers.Dense(10, activation=\"softmax\"),\n    ]\n   )\n    \nmyModel.compile( optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\nmyModel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:23:17.838948Z","iopub.execute_input":"2022-06-01T11:23:17.839268Z","iopub.status.idle":"2022-06-01T11:23:17.984714Z","shell.execute_reply.started":"2022-06-01T11:23:17.839235Z","shell.execute_reply":"2022-06-01T11:23:17.983976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Entrenamiento** </font>","metadata":{}},{"cell_type":"code","source":"early_stopping = EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=5, # how many epochs to wait before stopping\n    restore_best_weights=True,)\n\nepochs = 50\n\nX_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.1)\n\nhistory = myModel.fit(\n    X_train2, Y_train2,\n    validation_data=(X_val2, Y_val2),\n    batch_size=64,\n    epochs=epochs,\n    steps_per_epoch = X_train2.shape[0]//64,\n    callbacks=[early_stopping],\n    verbose=0, # suppress output since we'll plot the curves\n)\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[0:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n\nprint(max(history.history['accuracy']))\nprint(max(history.history['val_accuracy']))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:23:24.20984Z","iopub.execute_input":"2022-06-01T11:23:24.210495Z","iopub.status.idle":"2022-06-01T11:24:43.407183Z","shell.execute_reply.started":"2022-06-01T11:23:24.210454Z","shell.execute_reply":"2022-06-01T11:24:43.40643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Almacenamiento del modelo entrenado** </font>","metadata":{}},{"cell_type":"code","source":"myModel.save('myModelMNIST.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:24:57.208672Z","iopub.execute_input":"2022-06-01T11:24:57.209383Z","iopub.status.idle":"2022-06-01T11:24:57.291874Z","shell.execute_reply.started":"2022-06-01T11:24:57.209344Z","shell.execute_reply":"2022-06-01T11:24:57.291006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Carga del modelo entrenado** </font>","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\nmyModel = load_model('myModelMNIST.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:25:02.330801Z","iopub.execute_input":"2022-06-01T11:25:02.331661Z","iopub.status.idle":"2022-06-01T11:25:02.572372Z","shell.execute_reply.started":"2022-06-01T11:25:02.331612Z","shell.execute_reply":"2022-06-01T11:25:02.571538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Predicción** </font>","metadata":{}},{"cell_type":"code","source":"y_pred = myModel.predict(X_test)\nX_test__ = X_test.reshape(X_test.shape[0], 28, 28)\n\nfig, axis = plt.subplots(4, 4, figsize=(12, 14))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_test__[i], cmap='binary')\n    ax.set(title = f\"Predict Number is {y_pred[i].argmax()}\");","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:31:40.434438Z","iopub.execute_input":"2022-06-01T11:31:40.43497Z","iopub.status.idle":"2022-06-01T11:31:43.657541Z","shell.execute_reply.started":"2022-06-01T11:31:40.434925Z","shell.execute_reply":"2022-06-01T11:31:43.656882Z"},"trusted":true},"execution_count":null,"outputs":[]}]}