{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n \n#  **Introducción**\n\n<font size = 4>\nEl presente notebook, recoge el procedimiento seguido para la creación del modelo y su posterior fase de entrenamiento, validación y test.  \n<br> <br>\n \nLa base de datos utilizada para la creación del clasificador de imágenes se denomina **COVID-19 Radiography Database** y en su creación han participado un grupo de investigadores de la universidad de Qatar (Doha, Qatar), y de la universidad de Dhaka (Bangladesh).  \nSe compone por **21.165 muestras**  distribuidas en **4 categorías** : **Covid-19, neumonía viral, opacidad torácica y normales**. \n\n</font>","metadata":{}},{"cell_type":"markdown","source":"#  **1 <span style=\"color:#0386f7de\">|</span> Librerías** \n\n* <font size = 4>**Creación del modelo**: tensorflow, keras</font>\n* <font size = 4>**Procesamiento de los datos**: numpy, sklearn, pandas, glob, shutil</font>\n* <font size = 4>**Visualización de los datos**: matplotlib, cv2</font>\n","metadata":{}},{"cell_type":"code","source":"#IMPORTS\nimport numpy as np \nimport pandas as pd \nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, losses\nfrom tensorflow.keras.layers import BatchNormalization, Dropout, Conv2D, Flatten, Dense, MaxPooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nimport glob\nimport shutil\n\nimgSize = (299,299)\nnumClass = 3\nbatch_size = 64","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#  **2 <span style=\"color:#0386f7de\">|</span> Creacion de directorios temporales** \n\n<font size = 4>\n    Es necesario realizar un tratamiento de los datos, sin embargo, Kaggle no permite editar lo datos de entrada.\n    <br>\n    Para solucionar este inconveniente se crean un directorio temporal y se copian los archivos para realizarles el tratamiento adecuado\n</font>\n\n","metadata":{}},{"cell_type":"code","source":"if(os.path.isdir('../output/images/') == False):\n    os.makedirs('../output/images/')\nif(os.path.isdir('../output/images/COVID') == False):\n    os.makedirs('../output/images/COVID')\n    print(\"Creado directorio COVID\")\nif(os.path.isdir('../output/images/Lung_Opacity') == False):\n    os.makedirs('../output/images/Lung_Opacity')\n    print(\"Creado directorio Lung_Opacity\")\nif(os.path.isdir('../output/images/Normal') == False):\n    os.makedirs('../output/images/Normal')\n    print(\"Creado directorio Normal\")\nif(os.path.isdir('../output/images/Viral_Pneumonia') == False):\n    os.makedirs('../output/images/Viral_Pneumonia')\n    print(\"Creado directorio Pneumonia\")\n \npath = glob.glob('/kaggle/input/covid19-radiography-database/COVID-19_Radiography_Dataset/*/images/*.png')\n\nfor file in path:\n    if((os.path.split(file)[1]).split('-')[0] == 'COVID'):\n        dst = \"../output/images/COVID/\"\n        if(os.path.isfile(dst + os.path.split(file)[1]) == False):\n            shutil.copyfile(file, dst + os.path.split(file)[1])\n    elif((os.path.split(file)[1]).split('-')[0] == 'Lung_Opacity'):\n        dst = \"../output/images/Lung_Opacity/\"\n        if(os.path.isfile(dst + os.path.split(file)[1]) == False):\n            shutil.copyfile(file, dst + os.path.split(file)[1])\n    elif((os.path.split(file)[1]).split('-')[0] == 'Normal'):\n        dst = \"../output/images/Normal/\"\n        if(os.path.isfile(dst + os.path.split(file)[1]) == False):\n            shutil.copyfile(file, dst + os.path.split(file)[1])\n    elif((os.path.split(file)[1]).split('-')[0] == 'Viral Pneumonia'):\n        dst = \"../output/images/Viral_Pneumonia/\"\n        if(os.path.isfile(dst + 'Viral_Pneumonia-' + (os.path.split(file)[1]).split('-')[1]) == False):\n            shutil.copyfile(file, dst + os.path.split(file)[1])\n            os.rename(dst + os.path.split(file)[1], dst + 'Viral_Pneumonia-' + (os.path.split(file)[1]).split('-')[1])\n            \nprint(\"Todas las imagenes han sido almacenadas\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:15:11.320583Z","iopub.execute_input":"2022-05-31T18:15:11.32095Z","iopub.status.idle":"2022-05-31T18:15:11.656051Z","shell.execute_reply.started":"2022-05-31T18:15:11.320911Z","shell.execute_reply":"2022-05-31T18:15:11.654475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Método auxiliar para la comprobación de las rutas de las imagenes**","metadata":{}},{"cell_type":"code","source":"glob.glob('../output/images/*/*.png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3 <span style=\"color:#0386f7de\">|</span> Creacion del dataframe y clasificacion de las imagenes** \n\n<font size = 4>Se crea una estructura de datos denominada DataFrame con la librería Panda donde se almacenan las rutas y la categoría de las imágenes.  </font>","metadata":{}},{"cell_type":"code","source":"pathTemp = glob.glob('../output/images/*/*.png')\ncategories = []\nfilenames = []\n\ndictCategory = {'COVID': '0', 'Lung_Opacity': '1', 'Normal': '2', 'Viral_Pneumonia': '3'}\n\nfor file in pathTemp:\n    filenames.append(file)\n    categories.append(dictCategory[(os.path.split(file)[1]).split('-')[0]])\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})\n    \ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:15:25.5983Z","iopub.execute_input":"2022-05-31T18:15:25.598673Z","iopub.status.idle":"2022-05-31T18:15:25.713337Z","shell.execute_reply.started":"2022-05-31T18:15:25.598628Z","shell.execute_reply":"2022-05-31T18:15:25.712266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **4 <span style=\"color:#0386f7de\">|</span> Creacion del conjunto de entrenamiento, validación y test** \n<font size = 4>Se ha procedido a la division de las imagenes para la creación de los conjuntos</font>\n* <font size = 4>**Conjunto de entrenamiento**: 14.392 (68% del total)</font>\n* <font size = 4>**Conjunto de validación**: 3.598 (17% del total)</font>\n* <font size = 4>**Conjunto de test**: 3.175 (15% del total)</font>\n","metadata":{}},{"cell_type":"code","source":"train_filenames, test_filenames = train_test_split(df, test_size=0.15)\ntrain_filenames, val_filenames = train_test_split(train_filenames, test_size=0.2)\n\n\ntrain_generator = ImageDataGenerator(\n        rescale=1./255,\n    )\ntest_generator = ImageDataGenerator(\n        rescale=1./255,\n    )\n\nimage_train = train_generator.flow_from_dataframe(\n    train_filenames,\n    target_size=(imgSize),\n    x_col='filename',\n    y_col='category',\n    class_mode=\"categorical\",\n    shuffle=True,\n    batch_size=batch_size,\n)\n\nimage_val = train_generator.flow_from_dataframe(\n    val_filenames,\n    target_size=(imgSize),\n    x_col='filename',\n    y_col='category',\n    class_mode=\"categorical\",\n    shuffle=True,\n    batch_size=batch_size,\n)\n\nimage_test = test_generator.flow_from_dataframe(\n    test_filenames,\n    target_size=(imgSize),\n    x_col='filename',\n    y_col='category',\n    class_mode=\"categorical\",\n    shuffle=True,\n    batch_size=batch_size,\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:18:31.781483Z","iopub.execute_input":"2022-05-31T18:18:31.782521Z","iopub.status.idle":"2022-05-31T18:18:32.040965Z","shell.execute_reply.started":"2022-05-31T18:18:31.782446Z","shell.execute_reply":"2022-05-31T18:18:32.039317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Visualización de las imagenes**","metadata":{}},{"cell_type":"code","source":"class_names = image_train.class_indices\nclasses = list(class_names.keys())\n\ndictCategoryTr = {'0' : 'COVID', '1': 'Lung_Opacity', '2': 'Normal', '3': 'Viral_Pneumonia'}\n\nimages,labels = next(image_train)\nlabels = np.argmax(labels, axis=1)\nclass_dict = image_train.class_indices\nclass_dict_inv = dict((v, k) for k, v in class_dict.items())\ny_names = [class_dict_inv[key] for key in labels]\n\nplt.figure(figsize=(10, 10))\nfor image in images:\n    j  = 0\n    for i in range(4):\n        ax = plt.subplot(1, 4, i+1)\n        for k in range(len(labels)):\n            if labels[k] == j:\n                plt.imshow(images[k])\n                plt.title(dictCategoryTr[classes[i]])\n                plt.axis(\"off\")\n                break\nCreacion del modelo        j = j+1","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:21:52.903759Z","iopub.execute_input":"2022-05-31T18:21:52.904078Z","iopub.status.idle":"2022-05-31T18:22:01.692507Z","shell.execute_reply.started":"2022-05-31T18:21:52.904047Z","shell.execute_reply":"2022-05-31T18:22:01.691807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **5 <span style=\"color:#0386f7de\">|</span> Creacion del modelo** \n\n<font size = 4> </font>\n","metadata":{}},{"cell_type":"markdown","source":"<font size = 4>\n    Se detallan las características del modelo generado \n     \n</font> \n<font size = 4>\n    Se ha implementado una arquitectura CNN que consta de 6 capas. Las primeras 5 capas están formadas por una capa convolucional (Conv2D), seguida por una capa de normalización (BatchNormalization), una capa de MaxPooling2D y una capa de Dropout. \n</font> \n<br>\n<font size = 4>\n    La ultima capa está formada por una capa de flatten y una capa densa \n</font>","metadata":{}},{"cell_type":"code","source":"input_shape = (299, 299, 3)\n\nmyModel = keras.Sequential(\n    [\n        layers.Conv2D(128, kernel_size = (3, 3), activation=\"relu\", padding='same', input_shape = input_shape),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(2,2),\n        layers.Dropout(0.3),\n        layers.Conv2D(128, kernel_size = (3, 3), activation=\"relu\", padding='same', input_shape = input_shape),\n        layers.BatchNormalization(),\n        layers.Dropout(0.5),\n        layers.Conv2D(64, kernel_size = (3, 3), activation=\"relu\", padding='same'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        layers.Conv2D(64, kernel_size = (3, 3), activation=\"relu\", padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(2,2),\n        layers.Dropout(0.5),\n        layers.Conv2D(32, kernel_size = (3, 3), activation=\"relu\", padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(2,2),\n        layers.Dropout(0.2),\n        layers.Flatten(),\n        layers.Dense(4, activation=\"softmax\"),\n    ]\n   )\n\nmyModel.compile( optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\nmyModel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-26T08:07:18.453614Z","iopub.execute_input":"2022-05-26T08:07:18.453834Z","iopub.status.idle":"2022-05-26T08:07:21.242202Z","shell.execute_reply.started":"2022-05-26T08:07:18.453803Z","shell.execute_reply":"2022-05-26T08:07:21.241511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **6 <span style=\"color:#0386f7de\">|</span> Entrenamiento** \n<font size = 4>Se realiza el entrenamiento del modelo con el conjunto de entrenamiento y sus respectivas etiquetas.</font>\n   \n    \n<font size = 4> Se ha definido un *batch size* de 64 muestras y se ha fijado la duración del entrenamiento en un máximo de 75 épocas.</font>\n<font size = 4> Además, se ha activado un mecanismo de EarlyStopping orientado a la pérdida del modelo.</font>","metadata":{}},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', \n                               mode='min', \n                               patience = 5 ,\n                               restore_best_weights=True)\n\nmodel_chkpt = ModelCheckpoint('model_1.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n\nepoch = 75\n\n\nhistory = myModel.fit(\n    image_train,\n    validation_data=image_val,\n    batch_size=batch_size,\n    epochs=epoch,\n    callbacks=[model_chkpt ,early_stopping],\n    verbose=0, \n)\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[0:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n\nprint(max(history.history['accuracy']))\nprint(max(history.history['val_accuracy']))","metadata":{"execution":{"iopub.status.busy":"2022-05-26T08:07:31.321071Z","iopub.execute_input":"2022-05-26T08:07:31.321336Z","iopub.status.idle":"2022-05-26T08:38:03.831322Z","shell.execute_reply.started":"2022-05-26T08:07:31.321289Z","shell.execute_reply":"2022-05-26T08:38:03.830663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Almacenamiento manual del modelo entrenado** </font>","metadata":{}},{"cell_type":"code","source":"myModel.save('./model_1.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-26T09:08:56.919841Z","iopub.execute_input":"2022-05-26T09:08:56.920109Z","iopub.status.idle":"2022-05-26T09:08:56.999257Z","shell.execute_reply.started":"2022-05-26T09:08:56.920078Z","shell.execute_reply":"2022-05-26T09:08:56.998461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 4>**Carga del modelo entrenado** </font>","metadata":{}},{"cell_type":"code","source":"myModel = keras.models.load_model('../input/tfg-model/model_1.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-26T09:10:53.450761Z","iopub.execute_input":"2022-05-26T09:10:53.451004Z","iopub.status.idle":"2022-05-26T09:10:53.834156Z","shell.execute_reply.started":"2022-05-26T09:10:53.450978Z","shell.execute_reply":"2022-05-26T09:10:53.833467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **7 <span style=\"color:#0386f7de\">|</span> Validación**\n\n<font size = 4>Se utiliza el método evaluate disponible en la librería Keras para evaluar el rendimiento del modelo entrenado y comparar los resultados con los obtenidos previamente.</font>","metadata":{}},{"cell_type":"code","source":"# printing model accuracy for train and test data\n\ntrain_evaluation = myModel.evaluate(image_train)\nprint(f\"Train Accuracy: {train_evaluation[1] * 100:.2f}%\\n\")\n\ntest_evaluation = myModel.evaluate(image_val)\nprint(f\"Test Accuracy : {test_evaluation[1] * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-26T09:11:00.242824Z","iopub.execute_input":"2022-05-26T09:11:00.243074Z","iopub.status.idle":"2022-05-26T09:12:36.135551Z","shell.execute_reply.started":"2022-05-26T09:11:00.243047Z","shell.execute_reply":"2022-05-26T09:12:36.13486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **8 <span style=\"color:#0386f7de\">|</span> Predicción**\n<font size = 4>Para finalizar, se ha realizado una última comprobación con la función predict perteneciente a la librería Keras. Esta función predecirá la clasificación de las imágenes que se introduzcan como entrada en el modelo. </font>","metadata":{}},{"cell_type":"code","source":"class_namesT = image_test.class_indices\nprint(class_namesT)\nclassesT = list(class_namesT.keys())\n\nimagesT,labelsT = next(image_test)\nlabelsT = np.argmax(labelsT, axis=1)\nclass_dictT = image_test.class_indices\nclass_dict_invT = dict((v, k) for k, v in class_dictT.items())\ny_names = [class_dict_invT[key] for key in labelsT]\n\nplt.figure(figsize=(20,20))\ndictCatTr = {'0' : 'COVID', '1': 'Lung_Opacity', '2': 'Normal', '3': 'Viral_Pneumonia'}\nls = next(image_test)\n_, labelsT = ls\nlabelsT = np.argmax(labelsT, axis=1)\nprediction = myModel.predict(ls[0])\n\nfor i in range(16):\n    \n    pred = np.argmax(prediction[i])\n    \n    plt.subplot(4, 4, i+1)\n    plt.imshow(ls[0][i])\n    plt.title(f'Real:{dictCatTr[str(labelsT[i])]} \\n Predicción:{dictCatTr[str(pred)]}')\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:52:15.485759Z","iopub.execute_input":"2022-05-31T18:52:15.48604Z","iopub.status.idle":"2022-05-31T18:52:16.10616Z","shell.execute_reply.started":"2022-05-31T18:52:15.486001Z","shell.execute_reply":"2022-05-31T18:52:16.104955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-26T09:50:03.36527Z","iopub.execute_input":"2022-05-26T09:50:03.365735Z","iopub.status.idle":"2022-05-26T09:50:05.342125Z","shell.execute_reply.started":"2022-05-26T09:50:03.3657Z","shell.execute_reply":"2022-05-26T09:50:05.341225Z"},"trusted":true},"execution_count":null,"outputs":[]}]}